# LocalCowork Configuration
# Copy this file to .env and customize as needed
# All variables are prefixed with LOCALCOWORK_

# =============================================================================
# LLM Settings
# =============================================================================

# Ollama API endpoint
LOCALCOWORK_OLLAMA_URL=http://localhost:11434/api/generate

# Model to use (run 'ollama list' to see available models)
LOCALCOWORK_OLLAMA_MODEL=mistral

# Request timeout in seconds
LOCALCOWORK_OLLAMA_TIMEOUT=120

# Max tokens for LLM response
LOCALCOWORK_MAX_TOKENS=2048

# Context window size (increase for longer prompts/conversations)
# Common values: 4096, 8192, 16384, 32768 (depends on model support)
LOCALCOWORK_NUM_CTX=8192

# JSON parsing retry attempts
LOCALCOWORK_MAX_JSON_RETRIES=2

# =============================================================================
# Sandbox Settings (for isolated code execution)
# =============================================================================

# Execution timeout in seconds
LOCALCOWORK_SANDBOX_TIMEOUT=30

# Docker resource limits
LOCALCOWORK_SANDBOX_MEMORY_LIMIT=256m
LOCALCOWORK_SANDBOX_CPU_LIMIT=1
LOCALCOWORK_SANDBOX_PIDS_LIMIT=50
LOCALCOWORK_DOCKER_IMAGE=python:3.12-slim

# =============================================================================
# Server Settings (for web UI)
# =============================================================================

LOCALCOWORK_SERVER_HOST=127.0.0.1
LOCALCOWORK_SERVER_PORT=8000
LOCALCOWORK_SESSION_TIMEOUT=3600
LOCALCOWORK_MAX_HISTORY_MESSAGES=20

# =============================================================================
# Execution Settings
# =============================================================================

# Max code fix retries on error
LOCALCOWORK_MAX_CODE_RETRIES=2

# Enable parallel step execution
LOCALCOWORK_PARALLEL_EXECUTION=true

# Max auto-retry attempts with different approach on failure
LOCALCOWORK_MAX_RECOVERY_ATTEMPTS=3

# =============================================================================
# File Permission Settings
# =============================================================================

# Comma-separated list of allowed paths (glob patterns supported)
# Empty means allow all paths (with confirmation for sensitive ones)
# Examples: ~/projects,~/Documents,/tmp
LOCALCOWORK_ALLOWED_PATHS=

# Comma-separated list of denied paths (always blocked)
# These paths are NEVER accessible, even with confirmation
LOCALCOWORK_DENIED_PATHS=~/.ssh,~/.gnupg,~/.aws,~/.config/gcloud,/etc/passwd,/etc/shadow

# Require confirmation for paths outside allowed_paths
LOCALCOWORK_REQUIRE_PATH_CONFIRMATION=true

# Require approval before executing plans
LOCALCOWORK_REQUIRE_APPROVAL=true
